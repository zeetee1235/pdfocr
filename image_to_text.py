"""
ì´ë¯¸ì§€/PDF ë Œë”ë§ ê²°ê³¼ì—ì„œ OCR í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ëŠ” ëª¨ë“ˆ (OpenCV ì „ì²˜ë¦¬ + PSM ìë™ ìŠ¤ìœ• + í‘œìš© image_to_data ì§€ì›)

í•µì‹¬ ê°œì„ :
1) ì „ì²˜ë¦¬: ê·¸ë ˆì´/ì—…ìŠ¤ì¼€ì¼/ì´ì§„í™”/ë…¸ì´ì¦ˆ ì œê±°/í‘œ ì„  ì œê±°(ì˜µì…˜)
2) PSM ì—¬ëŸ¬ ê°œ ìë™ ì‹œë„ í›„ "ê°€ì¥ ê·¸ëŸ´ë“¯í•œ" ê²°ê³¼ ì„ íƒ
3) í‘œ(ê·¸ë¦¬ë“œ) ë¬¸ì„œì—ì„œ ìœ ë¦¬í•œ image_to_data ê¸°ë°˜ ì¶”ì¶œ/ì¬ì¡°ë¦½ ì˜µì…˜
"""

from __future__ import annotations

from dataclasses import dataclass
from pathlib import Path
from typing import Dict, List, Optional, Sequence, Tuple, Union

import cv2
import numpy as np
import pytesseract
from PIL import Image

PathLike = Union[str, Path]
TextDict = Dict[str, str]


# -----------------------------
# Utilities / Scoring
# -----------------------------
def _to_path(p: PathLike) -> Path:
    return p if isinstance(p, Path) else Path(p)


def _ensure_exists(p: Path) -> None:
    if not p.exists():
        raise FileNotFoundError(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {p}")


def _basic_text_quality_score(text: str) -> float:
    """
    OCR ê²°ê³¼ í…ìŠ¤íŠ¸ì˜ 'ê·¸ëŸ´ë“¯í•¨'ì„ ëŒ€ëµ ì ìˆ˜í™”.
    - í‘œ/ìˆ˜ì‹ ë¬¸ì„œë¼ë„ ìµœì†Œí•œ "ì½ì„ë§Œí•œ í…ìŠ¤íŠ¸"ê°€ ë§ìœ¼ë©´ ì ìˆ˜â†‘
    - ìˆ«ì/ê¸°í˜¸ ë‚œìˆ˜í™”ë©´ ì ìˆ˜â†“
    """
    if not text:
        return 0.0

    total = len(text)
    if total == 0:
        return 0.0

    letters = sum(ch.isalpha() for ch in text)  # í•œê¸€ë„ isalpha=True
    digits = sum(ch.isdigit() for ch in text)
    spaces = sum(ch.isspace() for ch in text)
    punct = total - letters - digits - spaces

    # ë¬¸ì ë¹„ì¤‘ì´ ë†’ì„ìˆ˜ë¡ ì¢‹ê²Œ, ê¸°í˜¸ ë¹„ì¤‘ì´ ë†’ì„ìˆ˜ë¡ ë‚˜ì˜ê²Œ
    letter_ratio = letters / total
    punct_ratio = punct / total

    # ë„ˆë¬´ ì§§ì€ ê²°ê³¼ëŠ” íŒ¨ë„í‹°
    length_bonus = min(total / 500.0, 1.0)  # 500ì ì´ìƒì´ë©´ 1.0

    # ìµœì¢… ì ìˆ˜: ê²½í—˜ì ìœ¼ë¡œ ì¡°í•©(ì™„ë²½í•œ ê¸°ì¤€ì€ ì•„ë‹˜)
    score = (letter_ratio * 2.2 + (digits / total) * 0.6 - punct_ratio * 1.4) * (0.4 + 0.6 * length_bonus)
    return float(score)


# -----------------------------
# Preprocessing (OpenCV)
# -----------------------------
@dataclass
class PreprocessOptions:
    upscale: float = 2.0               # ì‘ì€ ê¸€ì”¨ë©´ 2~3 ì¶”ì²œ
    denoise: bool = True
    binarize: bool = True
    deskew: bool = False              # ì¼œë©´ ëŠë¦´ ìˆ˜ ìˆìŒ (ê¸°ìš¸ì–´ì§„ ìŠ¤ìº”ì´ë©´ True ê³ ë ¤)
    remove_table_lines: bool = True   # í‘œê°€ ë§ìœ¼ë©´ True ì¶”ì²œ
    adaptive_thresh: bool = True      # ì¡°ëª… unevení•˜ë©´ Trueê°€ ìœ ë¦¬í•œ ê²½ìš° ë§ìŒ


def _pil_to_bgr(pil_img: Image.Image) -> np.ndarray:
    rgb = np.array(pil_img.convert("RGB"))
    bgr = cv2.cvtColor(rgb, cv2.COLOR_RGB2BGR)
    return bgr


def _upscale(img: np.ndarray, scale: float) -> np.ndarray:
    if scale is None or scale <= 1.0:
        return img
    h, w = img.shape[:2]
    return cv2.resize(img, (int(w * scale), int(h * scale)), interpolation=cv2.INTER_CUBIC)


def _maybe_denoise(gray: np.ndarray) -> np.ndarray:
    # ë„ˆë¬´ ê°•í•˜ë©´ ê¸€ìë„ ë­‰ê°œì§ˆ ìˆ˜ ìˆì–´ moderateë¡œ
    return cv2.fastNlMeansDenoising(gray, h=10, templateWindowSize=7, searchWindowSize=21)


def _binarize(gray: np.ndarray, adaptive: bool) -> np.ndarray:
    # ë¬¸ì„œ OCRì€ ë³´í†µ í°ë°”íƒ•/ê²€ì€ê¸€ì”¨ê°€ ì¢‹ìŒ
    if adaptive:
        # ì¡°ëª… ë¶ˆê· ì¼/ìŠ¤ìº” ì–¼ë£©ì— ê°•í•¨
        return cv2.adaptiveThreshold(
            gray, 255,
            cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
            cv2.THRESH_BINARY,
            35, 15
        )
    # ì „ì—­ threshold + Otsu
    _, th = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    return th


def _remove_lines(binary: np.ndarray) -> np.ndarray:
    """
    í‘œì˜ ê°€ë¡œ/ì„¸ë¡œ ì„ ì„ ì•½í•˜ê²Œ ì œê±°í•´ì„œ ê¸€ì ì¸ì‹ë¥ ì„ ì˜¬ë¦¼.
    (ì„ ì´ ë„ˆë¬´ ê°•í•˜ë©´ ê¸€ì ë©ì–´ë¦¬ ë¶„í• ì´ ë§ê°€ì§)
    """
    inv = 255 - binary  # ê¸€ì/ì„ ì´ í°ìƒ‰ì´ ë˜ê²Œ

    # ì»¤ë„ í¬ê¸°ëŠ” ì´ë¯¸ì§€ í¬ê¸°ì— ë¹„ë¡€í•˜ê²Œ
    h, w = binary.shape[:2]
    hk = max(10, w // 100)  # ê°€ë¡œì„  ì œê±°ìš©
    vk = max(10, h // 100)  # ì„¸ë¡œì„  ì œê±°ìš©

    horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (hk, 1))
    vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, vk))

    # ì„  ì„±ë¶„ ì¶”ì¶œ
    horizontal_lines = cv2.morphologyEx(inv, cv2.MORPH_OPEN, horizontal_kernel, iterations=1)
    vertical_lines = cv2.morphologyEx(inv, cv2.MORPH_OPEN, vertical_kernel, iterations=1)

    lines = cv2.bitwise_or(horizontal_lines, vertical_lines)

    # ì›ë³¸ì—ì„œ ì„ ì„ ë¹¼ì¤€ë‹¤(ë³µì›ì€ inpaintë¡œ ìì—°ìŠ¤ëŸ½ê²Œ)
    cleaned_inv = cv2.inpaint(inv, lines, inpaintRadius=2, flags=cv2.INPAINT_TELEA)

    # ë‹¤ì‹œ binary í˜•íƒœë¡œ
    cleaned = 255 - cleaned_inv
    return cleaned


def _deskew(binary: np.ndarray) -> np.ndarray:
    """
    ê°„ë‹¨í•œ deskew. (ê¸°ìš¸ê¸° ì‹¬í•˜ë©´ ê°œì„ , ì• ë§¤í•˜ë©´ ì˜¤íˆë ¤ ì•…í™” ê°€ëŠ¥)
    """
    # ê¸€ìê°€ ê²€ì€ìƒ‰ì´ì–´ì•¼ findNonZeroê°€ ìœ ë¦¬í•˜ë¯€ë¡œ invert ê³ ë ¤
    inv = 255 - binary
    coords = cv2.findNonZero(inv)
    if coords is None:
        return binary

    rect = cv2.minAreaRect(coords)
    angle = rect[-1]
    # OpenCV angle ê·œì¹™ ë³´ì •
    if angle < -45:
        angle = -(90 + angle)
    else:
        angle = -angle

    # ë„ˆë¬´ ì‘ì€ ê°ë„ëŠ” ë¬´ì‹œ
    if abs(angle) < 0.3:
        return binary

    h, w = binary.shape[:2]
    M = cv2.getRotationMatrix2D((w // 2, h // 2), angle, 1.0)
    rotated = cv2.warpAffine(binary, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)
    return rotated


def preprocess_for_ocr(pil_img: Image.Image, opt: PreprocessOptions) -> np.ndarray:
    """
    Tesseractì— ë„£ê¸° ì¢‹ì€ í˜•íƒœ(ê·¸ë ˆì´/ë°”ì´ë„ˆë¦¬)ë¡œ ì „ì²˜ë¦¬í•œ OpenCV ì´ë¯¸ì§€ ë°˜í™˜.
    ë°˜í™˜ì€ uint8 ë‹¨ì¼ ì±„ë„ ì´ë¯¸ì§€(0~255).
    """
    bgr = _pil_to_bgr(pil_img)
    bgr = _upscale(bgr, opt.upscale)

    gray = cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY)

    if opt.denoise:
        gray = _maybe_denoise(gray)

    if opt.binarize:
        img = _binarize(gray, adaptive=opt.adaptive_thresh)
    else:
        img = gray

    if opt.remove_table_lines and opt.binarize:
        img = _remove_lines(img)

    if opt.deskew and opt.binarize:
        img = _deskew(img)

    return img


# -----------------------------
# OCR: string vs data
# -----------------------------
@dataclass
class OcrOptions:
    lang: str = "kor+eng"
    oem: int = 1
    psm_candidates: Tuple[int, ...] = (6, 4, 1, 11)  # ë¬¸ì„œ/ë‹¤ë‹¨/ìë™/ìŠ¤íŒŒìŠ¤
    use_data_mode: bool = True                      # í‘œ/í˜¼í•© ë¬¸ì„œì—ì„œ ìœ ë¦¬
    min_conf: int = 35                              # data modeì—ì„œ conf í•„í„°
    keep_newlines: bool = True


def _tess_config(oem: int, psm: int) -> str:
    return f"--oem {oem} --psm {psm}"


def ocr_string(img_u8: np.ndarray, lang: str, config: str) -> str:
    # OpenCV ì´ë¯¸ì§€ë¥¼ PILë¡œ ë³€í™˜ (tesseractê°€ ë” ì•ˆì •ì ì¸ ê²½ìš°ê°€ ë§ìŒ)
    pil = Image.fromarray(img_u8)
    return pytesseract.image_to_string(pil, lang=lang, config=config)


def ocr_data_reconstruct_lines(img_u8: np.ndarray, lang: str, config: str, min_conf: int) -> str:
    """
    image_to_dataë¡œ (word ë‹¨ìœ„ + ì¢Œí‘œ + confidence) ê°€ì ¸ì™€ì„œ
    - conf ë‚®ì€ í† í° ì œê±°
    - line_num ê¸°ë°˜ìœ¼ë¡œ ë¼ì¸ ì¬ì¡°ë¦½
    í‘œ ë¬¸ì„œì—ì„œ "ì´ìƒí•œ ë‚œìˆ˜í™”"ë¥¼ ì¤„ì´ëŠ” ë° ë„ì›€ ë˜ëŠ” í¸.
    """
    pil = Image.fromarray(img_u8)
    data = pytesseract.image_to_data(pil, lang=lang, config=config, output_type=pytesseract.Output.DICT)

    n = len(data.get("text", []))
    if n == 0:
        return ""

    lines: Dict[Tuple[int, int, int], List[Tuple[int, str]]] = {}
    # key: (block_num, par_num, line_num), value: [(left, text), ...]
    for i in range(n):
        txt = (data["text"][i] or "").strip()
        if not txt:
            continue
        try:
            conf = int(float(data["conf"][i]))
        except Exception:
            conf = -1
        if conf != -1 and conf < min_conf:
            continue

        key = (data["block_num"][i], data["par_num"][i], data["line_num"][i])
        left = int(data["left"][i])
        lines.setdefault(key, []).append((left, txt))

    if not lines:
        return ""

    # ë¼ì¸ ì •ë ¬: block, par, line ìˆœ
    out_lines: List[str] = []
    for key in sorted(lines.keys()):
        words = sorted(lines[key], key=lambda x: x[0])  # left ê¸°ì¤€
        out_lines.append(" ".join(w for _, w in words))

    return "\n".join(out_lines)


def extract_text_best_effort(
    pil_img: Image.Image,
    pp: PreprocessOptions,
    ocr_opt: OcrOptions,
) -> Tuple[str, Dict[str, float]]:
    """
    PSM í›„ë³´ë¥¼ ì—¬ëŸ¬ ê°œ ëŒë ¤ë³´ê³ , ê°€ì¥ ì ìˆ˜ ë†’ì€ ê²°ê³¼ë¥¼ ì„ íƒ.
    - data_mode ê²°ê³¼ì™€ string ê²°ê³¼ ì¤‘ ë” ë‚˜ì€ ìª½ì„ ì„ íƒ(ì˜µì…˜)
    ë°˜í™˜: (best_text, debug_scores)
    """
    img_u8 = preprocess_for_ocr(pil_img, pp)

    best_text = ""
    best_score = float("-inf")
    debug: Dict[str, float] = {}

    for psm in ocr_opt.psm_candidates:
        cfg = _tess_config(ocr_opt.oem, psm)

        # 1) ê¸°ë³¸ string mode
        try:
            txt_s = ocr_string(img_u8, lang=ocr_opt.lang, config=cfg)
        except Exception:
            txt_s = ""
        score_s = _basic_text_quality_score(txt_s)
        debug[f"psm{psm}_string"] = score_s

        # 2) data mode (í‘œ/í˜¼í•© ë¬¸ì„œì— ë„ì›€)
        txt_d = ""
        score_d = float("-inf")
        if ocr_opt.use_data_mode:
            try:
                txt_d = ocr_data_reconstruct_lines(img_u8, lang=ocr_opt.lang, config=cfg, min_conf=ocr_opt.min_conf)
            except Exception:
                txt_d = ""
            score_d = _basic_text_quality_score(txt_d)
            debug[f"psm{psm}_data"] = score_d

        # í›„ë³´ë“¤ ì¤‘ ìµœê³ ë¥¼ ì±„íƒ
        if score_s > best_score:
            best_score = score_s
            best_text = txt_s
        if score_d > best_score:
            best_score = score_d
            best_text = txt_d

    if not ocr_opt.keep_newlines:
        best_text = " ".join(best_text.split())

    return best_text, debug


# -----------------------------
# Public API
# -----------------------------
def extract_text_from_image(
    image_path: PathLike,
    lang: str = "kor+eng",
    preprocess: Optional[PreprocessOptions] = None,
    ocr_options: Optional[OcrOptions] = None,
) -> str:
    """
    ë‹¨ì¼ ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ì „ì²˜ë¦¬ + PSM ìë™ ìŠ¤ìœ• + data mode ì˜µì…˜)

    Args:
        image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
        lang: OCR ì–¸ì–´ (ê¸°ë³¸ "kor+eng")
        preprocess: ì „ì²˜ë¦¬ ì˜µì…˜
        ocr_options: OCR ì˜µì…˜

    Returns:
        ì¶”ì¶œëœ í…ìŠ¤íŠ¸
    """
    p = _to_path(image_path)
    _ensure_exists(p)

    pp = preprocess or PreprocessOptions()
    oo = ocr_options or OcrOptions()
    oo.lang = lang  # í˜¸ì¶œìê°€ langì„ ë„˜ê¸°ë©´ ë°˜ì˜

    try:
        with Image.open(p) as pil_img:
            text, _debug = extract_text_best_effort(pil_img, pp, oo)
        return text
    except Exception as exc:
        raise RuntimeError(f"ì´ë¯¸ì§€ {p}ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {exc}") from exc


def extract_text_from_images(
    image_paths: Sequence[PathLike],
    lang: str = "kor+eng",
    preprocess: Optional[PreprocessOptions] = None,
    ocr_options: Optional[OcrOptions] = None,
    show_debug: bool = False,
) -> TextDict:
    """
    ì—¬ëŸ¬ ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ

    Args:
        image_paths: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        lang: OCR ì–¸ì–´ (ê¸°ë³¸ "kor+eng")
        preprocess: ì „ì²˜ë¦¬ ì˜µì…˜
        ocr_options: OCR ì˜µì…˜
        show_debug: psmë³„ ì ìˆ˜ ì¶œë ¥

    Returns:
        {ì´ë¯¸ì§€ ê²½ë¡œ(str): ì¶”ì¶œëœ í…ìŠ¤íŠ¸}
    """
    paths = [_to_path(p) for p in image_paths]

    pp = preprocess or PreprocessOptions()
    oo = ocr_options or OcrOptions()
    oo.lang = lang

    print(f"ğŸ” OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œì‘ (ì–¸ì–´: {lang})")
    print(f"   ì´ {len(paths)}ê°œ ì´ë¯¸ì§€ ì²˜ë¦¬ ì˜ˆì •\n")

    results: TextDict = {}

    for i, p in enumerate(paths, start=1):
        print(f"  [{i}/{len(paths)}] ì²˜ë¦¬ ì¤‘: {p.name}")
        try:
            _ensure_exists(p)
            with Image.open(p) as pil_img:
                text, debug_scores = extract_text_best_effort(pil_img, pp, oo)

            results[str(p)] = text
            print(f"    âœ“ ì¶”ì¶œëœ í…ìŠ¤íŠ¸: {len(text)} ê¸€ì")

            if show_debug:
                # ìƒìœ„ 5ê°œë§Œ ë³´ê¸° ì¢‹ê²Œ
                top = sorted(debug_scores.items(), key=lambda kv: kv[1], reverse=True)[:5]
                top_str = ", ".join(f"{k}:{v:.3f}" for k, v in top)
                print(f"    Â· ì ìˆ˜(top): {top_str}")

        except Exception as exc:
            print(f"    âœ— ì˜¤ë¥˜: {exc}")
            results[str(p)] = ""

    print(f"\nâœ“ OCR ì¶”ì¶œ ì™„ë£Œ\n")
    return results


def save_extracted_text(text_dict: TextDict, output_path: PathLike = "output/extracted_text.txt") -> None:
    """
    ì¶”ì¶œëœ í…ìŠ¤íŠ¸ë¥¼ íŒŒì¼ë¡œ ì €ì¥
    """
    output_path = _to_path(output_path)
    output_dir = output_path.parent

    if output_dir and not output_dir.exists():
        output_dir.mkdir(parents=True, exist_ok=True)
        print(f"âœ“ ë””ë ‰í† ë¦¬ ìƒì„±: {output_dir}")

    print(f"ğŸ’¾ í…ìŠ¤íŠ¸ íŒŒì¼ ì €ì¥ ì¤‘: {output_path}")

    with output_path.open("w", encoding="utf-8") as f:
        for i, (image_path, text) in enumerate(sorted(text_dict.items()), start=1):
            page_name = Path(image_path).name
            f.write(f"{'='*80}\n")
            f.write(f"í˜ì´ì§€ {i}: {page_name}\n")
            f.write(f"{'='*80}\n\n")
            f.write(text)
            f.write("\n\n\n")

    print(f"âœ“ ì €ì¥ ì™„ë£Œ: {output_path}\n")


# -----------------------------
# CLI
# -----------------------------
if __name__ == "__main__":  # pragma: no cover - CLI helper
    import argparse
    import glob
    import sys

    parser = argparse.ArgumentParser(description="OpenCV ì „ì²˜ë¦¬ + PSM ìë™ ìŠ¤ìœ• + data mode OCR")
    parser.add_argument("image_dir", type=str, help="ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ (ì˜ˆ: ./pages)")
    parser.add_argument("--lang", type=str, default="kor+eng", help='OCR ì–¸ì–´ (ê¸°ë³¸ "kor+eng")')
    parser.add_argument("--ext", type=str, default="png", help='í™•ì¥ì (ê¸°ë³¸ "png")')
    parser.add_argument("--out", type=str, default="output/extracted_text.txt", help="ì¶œë ¥ txt ê²½ë¡œ")
    parser.add_argument("--no-lines", action="store_true", help="í‘œ ì„  ì œê±° ë„ê¸°")
    parser.add_argument("--deskew", action="store_true", help="deskew ì¼œê¸°(ëŠë¦´ ìˆ˜ ìˆìŒ)")
    parser.add_argument("--upscale", type=float, default=2.0, help="ì—…ìŠ¤ì¼€ì¼ ë°°ìˆ˜ (ê¸°ë³¸ 2.0)")
    parser.add_argument("--no-data", action="store_true", help="image_to_data ëª¨ë“œ ë„ê¸°")
    parser.add_argument("--min-conf", type=int, default=35, help="data mode ìµœì†Œ confidence (ê¸°ë³¸ 35)")
    parser.add_argument("--debug", action="store_true", help="psmë³„ ì ìˆ˜ ì¶œë ¥")

    args = parser.parse_args()

    image_dir = _to_path(args.image_dir)
    if not image_dir.exists():
        print(f"ì˜¤ë¥˜: ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_dir}")
        sys.exit(1)

    pattern = str(image_dir / f"*.{args.ext.lstrip('.')}")
    image_files = sorted(glob.glob(pattern))

    if not image_files:
        print(f"ì˜¤ë¥˜: {image_dir}ì—ì„œ '*.{args.ext}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        sys.exit(1)

    pp = PreprocessOptions(
        upscale=args.upscale,
        remove_table_lines=not args.no_lines,
        deskew=args.deskew,
    )
    oo = OcrOptions(
        lang=args.lang,
        use_data_mode=not args.no_data,
        min_conf=args.min_conf,
    )

    try:
        text_results = extract_text_from_images(
            image_files,
            lang=args.lang,
            preprocess=pp,
            ocr_options=oo,
            show_debug=args.debug,
        )
        save_extracted_text(text_results, args.out)
        print("í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ì €ì¥ ì™„ë£Œ!")
    except Exception as exc:
        print(f"ì˜¤ë¥˜: {exc}")
        sys.exit(1)
